{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixx7cS4DfEXk"
   },
   "source": [
    "# Using SPMM model to predict BBB permeability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRcXhZuTw72J",
    "outputId": "f60e307a-fa4a-4dd0-cec4-4490dae50915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1jNVII-ktlV17p6bCdzw0TiPsb6lGNgWY\n",
      "From (redirected): https://drive.google.com/uc?id=1jNVII-ktlV17p6bCdzw0TiPsb6lGNgWY&confirm=t&uuid=ca1b910b-bf92-4a1f-bb95-83727b6000c9\n",
      "To: /content/Pretrain/checkpoint_SPMM.ckpt\n",
      "100% 2.36G/2.36G [00:54<00:00, 43.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!mkdir -p /content/Pretrain\n",
    "!gdown --id 1jNVII-ktlV17p6bCdzw0TiPsb6lGNgWY -O /content/Pretrain/checkpoint_SPMM.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkAmbkcWeQtA",
    "outputId": "96a6c0e7-1f58-490f-d911-7c03edf6dc48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete: train.csv, validation.csv, test.csv created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"./combined_bbb_classification.csv\")\n",
    "\n",
    "# First split: train (80%) and temp (20%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: validation (10%) and test (10%)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save to CSV files\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "val_df.to_csv(\"validation.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "print(\"Split complete: train.csv, validation.csv, test.csv created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZptbV-K7wpeN",
    "outputId": "3699af57-7de0-4c7a-92ab-3277d96a4634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SPMM'...\n",
      "remote: Enumerating objects: 329, done.\u001b[K\n",
      "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
      "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
      "remote: Total 329 (delta 101), reused 69 (delta 54), pack-reused 184 (from 1)\u001b[K\n",
      "Receiving objects: 100% (329/329), 695.54 KiB | 3.33 MiB/s, done.\n",
      "Resolving deltas: 100% (178/178), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jinhojsk515/SPMM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jzKVC8BqFxKs",
    "outputId": "244b3aab-9e52-47b6-a1ea-e7d687e3650d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Get:2 https://cli.github.com/packages stable InRelease [3,917 B]               \n",
      "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,813 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
      "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,373 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,988 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,778 kB]\n",
      "Fetched 25.3 MB in 4s (6,527 kB/s)\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
      "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
      "python3-distutils set to manually installed.\n",
      "python3.10 is already the newest version (3.10.12-1~22.04.11).\n",
      "python3.10 set to manually installed.\n",
      "The following NEW packages will be installed:\n",
      "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
      "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
      "Need to get 2,481 kB of archives.\n",
      "After this operation, 2,754 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.7 [1,683 kB]\n",
      "Get:2 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-setuptools-whl all 68.1.2-2~jammy3 [792 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.11 [5,726 B]\n",
      "Fetched 2,481 kB in 1s (1,720 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package python3-pip-whl.\n",
      "(Reading database ... 126675 files and directories currently installed.)\n",
      "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.7_all.deb ...\n",
      "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\n",
      "Selecting previously unselected package python3-setuptools-whl.\n",
      "Preparing to unpack .../python3-setuptools-whl_68.1.2-2~jammy3_all.deb ...\n",
      "Unpacking python3-setuptools-whl (68.1.2-2~jammy3) ...\n",
      "Selecting previously unselected package python3.10-venv.\n",
      "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.11_amd64.deb ...\n",
      "Unpacking python3.10-venv (3.10.12-1~22.04.11) ...\n",
      "Setting up python3-setuptools-whl (68.1.2-2~jammy3) ...\n",
      "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\n",
      "Setting up python3.10-venv (3.10.12-1~22.04.11) ...\n",
      "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
      "\n",
      "  Selection    Path                 Priority   Status\n",
      "------------------------------------------------------------\n",
      "* 0            /usr/bin/python3.12   2         auto mode\n",
      "  1            /usr/bin/python3.10   1         manual mode\n",
      "  2            /usr/bin/python3.12   2         manual mode\n",
      "\n",
      "Press <enter> to keep the current choice[*], or type selection number: 1\n",
      "update-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in manual mode\n",
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "#switching the colab python environment to older version to support requirements.txt module versions\n",
    "!sudo apt-get update -y\n",
    "!sudo apt-get install python3.10 python3.10-distutils python3.10-venv -y\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
    "!sudo update-alternatives --config python3  # choose 3.10\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbRRnlbNMz4V",
    "outputId": "1223a9d1-9718-4ddf-8243-2b36ad69aa8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-18 04:48:19--  https://bootstrap.pypa.io/get-pip.py\n",
      "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
      "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2148718 (2.0M) [text/x-python]\n",
      "Saving to: ‘get-pip.py’\n",
      "\n",
      "get-pip.py          100%[===================>]   2.05M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2025-10-18 04:48:20 (57.1 MB/s) - ‘get-pip.py’ saved [2148718/2148718]\n",
      "\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pip-25.2 setuptools-80.9.0 wheel-0.45.1\n"
     ]
    }
   ],
   "source": [
    "!wget https://bootstrap.pypa.io/get-pip.py\n",
    "!python get-pip.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLgGJHqPM2vk",
    "outputId": "5b0a85e2-ebea-49a0-c487-923a864e88bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PySMILESutils@ git+https://github.com/MolecularAI/pysmilesutils.git@b1e7ced15a42e18e629b984816020b1f0b0a2aa3 (from -r requirements.txt (line 3))\n",
      "  Cloning https://github.com/MolecularAI/pysmilesutils.git (to revision b1e7ced15a42e18e629b984816020b1f0b0a2aa3) to /tmp/pip-install-1oxo3j7l/pysmilesutils_c1ad4367b2de45c581b027ba3a5eae30\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/MolecularAI/pysmilesutils.git /tmp/pip-install-1oxo3j7l/pysmilesutils_c1ad4367b2de45c581b027ba3a5eae30\n",
      "  Running command git rev-parse -q --verify 'sha^b1e7ced15a42e18e629b984816020b1f0b0a2aa3'\n",
      "  Running command git fetch -q https://github.com/MolecularAI/pysmilesutils.git b1e7ced15a42e18e629b984816020b1f0b0a2aa3\n",
      "  Running command git checkout -q b1e7ced15a42e18e629b984816020b1f0b0a2aa3\n",
      "  Resolved https://github.com/MolecularAI/pysmilesutils.git to commit b1e7ced15a42e18e629b984816020b1f0b0a2aa3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting numpy==1.24.3 (from -r requirements.txt (line 1))\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting pandas==2.0.2 (from -r requirements.txt (line 2))\n",
      "  Downloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting pytorch-lightning==2.0.3 (from -r requirements.txt (line 4))\n",
      "  Downloading pytorch_lightning-2.0.3-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting rdkit==2023.3.1 (from -r requirements.txt (line 5))\n",
      "  Downloading rdkit-2023.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers==0.13.3 (from -r requirements.txt (line 6))\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torch==1.13.1 (from -r requirements.txt (line 7))\n",
      "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting tqdm==4.65.0 (from -r requirements.txt (line 8))\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
      "Collecting transformers==4.30.1 (from -r requirements.txt (line 9))\n",
      "  Downloading transformers-4.30.1-py3-none-any.whl.metadata (113 kB)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 10))\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas==2.0.2->-r requirements.txt (line 2))\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas==2.0.2->-r requirements.txt (line 2))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas==2.0.2->-r requirements.txt (line 2))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting PyYAML>=5.4 (from pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting fsspec>2021.06.0 (from fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting packaging>=17.1 (from pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting Pillow (from rdkit==2023.3.1->-r requirements.txt (line 5))\n",
      "  Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->-r requirements.txt (line 7))\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->-r requirements.txt (line 7))\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->-r requirements.txt (line 7))\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->-r requirements.txt (line 7))\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting filelock (from transformers==4.30.1->-r requirements.txt (line 9))\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.30.1->-r requirements.txt (line 9))\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.30.1->-r requirements.txt (line 9))\n",
      "  Downloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers==4.30.1->-r requirements.txt (line 9))\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.30.1->-r requirements.txt (line 9))\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 7)) (80.9.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 7)) (0.45.1)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.1->-r requirements.txt (line 9))\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn->-r requirements.txt (line 10))\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 10))\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 10))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading aiohttp-3.13.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.2->-r requirements.txt (line 2)) (1.16.0)\n",
      "INFO: pip is looking at multiple versions of torchmetrics to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==2.0.3->-r requirements.txt (line 4))\n",
      "  Downloading torchmetrics-1.8.1-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading torchmetrics-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is still looking at multiple versions of torchmetrics to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchmetrics-1.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading torchmetrics-1.6.2-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.30.1->-r requirements.txt (line 9))\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.30.1->-r requirements.txt (line 9))\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.30.1->-r requirements.txt (line 9))\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m147.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.0.3-py3-none-any.whl (720 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.6/720.6 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rdkit-2023.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m163.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m  \u001b[33m0:00:23\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m157.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading aiohttp-3.13.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.3/770.3 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (789 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.9/789.9 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m138.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Building wheels for collected packages: PySMILESutils\n",
      "\u001b[33m  DEPRECATION: Building 'PySMILESutils' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'PySMILESutils'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for PySMILESutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for PySMILESutils: filename=pysmilesutils-1.1.0-py3-none-any.whl size=21245 sha256=7018ac97ca0a8f0f6f1fdb16e81af46a8b163091b8728d1087d552105a75dac4\n",
      "  Stored in directory: /root/.cache/pip/wheels/88/80/d7/9621a4572a88df7742454f23651646fdcdb48bb235ec7e67b6\n",
      "Successfully built PySMILESutils\n",
      "Installing collected packages: tokenizers, pytz, PySMILESutils, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, safetensors, regex, PyYAML, python-dateutil, propcache, Pillow, packaging, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, joblib, idna, hf-xet, fsspec, frozenlist, filelock, charset_normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, scipy, requests, rdkit, pandas, nvidia-cudnn-cu11, multidict, lightning-utilities, aiosignal, yarl, torch, scikit-learn, huggingface-hub, transformers, torchmetrics, aiohttp, pytorch-lightning\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/46\u001b[0m [pytorch-lightning]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Pillow-12.0.0 PySMILESutils-1.1.0 PyYAML-6.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.4.0 certifi-2025.10.5 charset_normalizer-3.4.4 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.35.3 idna-3.11 joblib-1.5.2 lightning-utilities-0.15.2 multidict-6.7.0 numpy-1.24.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 packaging-25.0 pandas-2.0.2 propcache-0.4.1 python-dateutil-2.9.0.post0 pytorch-lightning-2.0.3 pytz-2025.2 rdkit-2023.3.1 regex-2025.9.18 requests-2.32.5 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.15.3 threadpoolctl-3.6.0 tokenizers-0.13.3 torch-1.13.1 torchmetrics-1.5.2 tqdm-4.65.0 transformers-4.30.1 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTQtIOHPAstN",
    "outputId": "2aaa879f-7d11-4272-c2df-e337d40ac1d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: bbbp\n",
      "7701 961 964\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Creating model\n",
      "#parameters: 43746050\n",
      "LOADING PRETRAINED MODEL..\n",
      "load checkpoint from ./Pretrain/checkpoint_SPMM.ckpt\n",
      "TRAIN 0\n",
      "loss=0.3371, lr=0.000030: 100% 481/481 [00:38<00:00, 12.50it/s]\n",
      "VALID AUROC: 0.9493\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "TEST AUROC: 0.9569\n",
      "TRAIN 1\n",
      "Train Epoch: [1]:   0% 0/481 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loss=0.2767, lr=0.000029: 100% 481/481 [00:36<00:00, 13.11it/s]\n",
      "VALID AUROC: 0.9549\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "TEST AUROC: 0.9622\n",
      "TRAIN 2\n",
      "Train Epoch: [2]:   0% 0/481 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loss=0.1822, lr=0.000028: 100% 481/481 [00:36<00:00, 13.35it/s]\n",
      "VALID AUROC: 0.9535\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "TEST AUROC: 0.9636\n",
      "TRAIN 3\n",
      "Train Epoch: [3]:   0% 0/481 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loss=0.0388, lr=0.000025: 100% 481/481 [00:36<00:00, 13.18it/s]\n",
      "VALID AUROC: 0.9543\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "TEST AUROC: 0.9645\n",
      "TRAIN 4\n",
      "Train Epoch: [4]:   0% 0/481 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loss=0.0423, lr=0.000021: 100% 481/481 [00:36<00:00, 13.04it/s]\n",
      "VALID AUROC: 0.9538\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "TEST AUROC: 0.9637\n",
      "TRAIN 5\n",
      "Train Epoch: [5]:   0% 0/481 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loss=0.0235, lr=0.000018: 100% 481/481 [00:36<00:00, 13.09it/s]\n",
      "VALID AUROC: 0.9499\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "TEST AUROC: 0.9653\n",
      "TRAIN 6\n",
      "Train Epoch: [6]:   0% 0/481 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loss=0.0531, lr=0.000014: 100% 481/481 [00:36<00:00, 13.18it/s]\n",
      "VALID AUROC: 0.9510\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "TEST AUROC: 0.9662\n",
      "TRAIN 7\n",
      "Train Epoch: [7]:   0% 0/481 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loss=0.0830, lr=0.000010: 100% 481/481 [00:36<00:00, 13.25it/s]\n",
      "VALID AUROC: 0.9499\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "TEST AUROC: 0.9657\n",
      "TRAIN 8\n",
      "Train Epoch: [8]:   0% 0/481 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loss=0.0706, lr=0.000007: 100% 481/481 [00:36<00:00, 13.29it/s]\n",
      "VALID AUROC: 0.9505\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "TEST AUROC: 0.9656\n",
      "TRAIN 9\n",
      "Train Epoch: [9]:   0% 0/481 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loss=0.0910, lr=0.000006: 100% 481/481 [00:36<00:00, 13.25it/s]\n",
      "VALID AUROC: 0.9502\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "TEST AUROC: 0.9655\n",
      "Training time 0:06:59\n",
      "DATASET: bbbp \tTest set AUROC of the checkpoint with best validation AUROC: 0.9622068972001278\n",
      "Model saved as spmm_classifier.pth\n",
      "\n",
      "Test prediction for benzene (c1ccccc1):\n",
      "  BBB Permeable: False\n",
      "  Confidence: 0.9997\n",
      "  Probabilities: [Non-permeable: 0.9997, Permeable: 0.0003]\n"
     ]
    }
   ],
   "source": [
    "#change path iin d_classification.py first - change to 'BBB' in dataset.py\n",
    "!python bbb_model.py --checkpoint './Pretrain/checkpoint_SPMM.ckpt' --name 'bbbp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nT38ugIEUHm8",
    "outputId": "c3f5058b-ec9e-401a-eaaf-cbaa17b5f617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'MixedPrecisionPlugin', 'hparams_name', 'hyper_parameters'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint = torch.load('./Pretrain/checkpoint_SPMM.ckpt', map_location='cpu', weights_only=False)\n",
    "print(checkpoint.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qa_DcZ92V3-y"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLOiyog_fCls"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
