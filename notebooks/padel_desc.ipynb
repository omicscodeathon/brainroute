{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9bde6d5-598e-47f2-a28c-39b95964be30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1437482-30a6-4b97-b646-e990df49a006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  289k    0  289k    0     0   508k      0 --:--:-- --:--:-- --:--:--  518k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  289k    0  289k    0     0   688k      0 --:--:-- --:--:-- --:--:--  698k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o padel.zip https://github.com/dataprofessor/bioinformatics/raw/master/padel.zip\n",
    "!curl -L -o padel.sh https://github.com/dataprofessor/bioinformatics/raw/master/padel.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24ce2512-3ce3-4384-9d4a-1cbcd6debc30",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3744295861.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfile padel.zip      # check actual file type\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!ls -lh padel.zip    # check file size\n",
    "file padel.zip      # check actual file type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff24d1ae-a50d-497a-afe5-4d46f0f96323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  289k    0  289k    0     0   555k      0 --:--:-- --:--:-- --:--:--  561k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o padel.zip https://github.com/dataprofessor/bioinformatics/raw/master/padel.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d746f0d-5883-4209-a3f9-205f68a4ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  padel.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of padel.zip or\n",
      "        padel.zip.zip, and cannot find padel.zip.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "!unzip padel.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8920e2a-808a-4e56-af88-888d17653939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating PaDEL descriptors for 9637 molecules...\n",
      "An error occurred. Make sure Java is installed and in your PATH.\n",
      "Error details: PaDEL-Descriptor failed on temp_molecules.smi. Ensure input structure is correct.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from padelpy import from_smiles\n",
    "import os\n",
    "\n",
    "# 1. Load your data\n",
    "input_file = '../data/combined_bbb_classification_fixed.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 2. Prepare data for PaDEL\n",
    "# PaDEL accepts a .smi file with columns: [SMILES] [Name]\n",
    "# We'll create a unique ID for each molecule to ensure accuracy (handling missing/duplicate names)\n",
    "df['unique_id'] = 'Mol_' + df.index.astype(str) + '_' + df['name'].fillna('Unknown').astype(str)\n",
    "\n",
    "# Select only SMILES and ID, drop any rows without SMILES\n",
    "smi_data = df[['smiles', 'unique_id']].dropna(subset=['smiles'])\n",
    "\n",
    "# Save to a temporary .smi file (tab-separated, no header)\n",
    "smi_file = 'temp_molecules.smi'\n",
    "smi_data.to_csv(smi_file, sep='\\t', index=False, header=False)\n",
    "\n",
    "# 3. Calculate Descriptors\n",
    "# descriptors=True calculates 1D/2D descriptors. \n",
    "# fingerprints=True would add fingerprints (PubChem, etc.) but takes longer.\n",
    "output_file = 'padel_descriptors_output.csv'\n",
    "print(f\"Calculating PaDEL descriptors for {len(smi_data)} molecules...\")\n",
    "\n",
    "try:\n",
    "    # This function calls the PaDEL-Descriptor Java executable\n",
    "    from_smiles(\n",
    "        smi_file, \n",
    "        output_csv=output_file, \n",
    "        descriptors=True,   # Set to True for standard descriptors\n",
    "        fingerprints=False, # Set to True if you also need fingerprints (slower)\n",
    "        threads=4           # Use 4 CPU cores for speed\n",
    "    )\n",
    "    print(f\"Success! Descriptors saved to: {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred. Make sure Java is installed and in your PATH.\")\n",
    "    print(f\"Error details: {e}\")\n",
    "\n",
    "finally:\n",
    "    # 4. Cleanup temporary file\n",
    "    if os.path.exists(smi_file):\n",
    "        os.remove(smi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80125fc6-a86e-45f5-82c8-a527907d12a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70fb0b56-4968-4e73-8b58-7e97bea1d840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new output file: padel_results_loop.csv\n",
      "Processing 9637 molecules one by one...\n",
      "Row 0 (sulphasalazine): Success\n",
      "Row 1 (moxalactam): Success\n",
      "Row 2 (clioquinol): Success\n",
      "Row 3 (bbcpd11 (cimetidine analog) (y-g13)): Success\n",
      "Row 4 (schembl614298): Success\n",
      "Row 5 (uk-240,455): Success\n",
      "Row 6 (morphine-6-glucuronide): Success\n",
      "Row 7 (nitrofurantoin): Success\n",
      "Row 8 (l-701,324): Success\n",
      "Row 9 (33419-42-0): Success\n",
      "Row 10 (icotidine): Success\n",
      "Row 11 (ro 64-0802): Success\n",
      "Row 12 (temelastine): Success\n",
      "Row 13 (disodium;(6r,7s)-7-[[4-(2-amino-1-carboxylato-2-oxoethylidene)-1,3-dithietane-2-carbonyl]amino]-7-methoxy-3-[(1-methyltetrazol-5-yl)sulfanylmethyl]-8-oxo-5-thia-1-azabicyclo[4.2.0]oct-2-ene-2-carboxylate): Success\n",
      "Row 14 (cefotetan): Success\n",
      "Row 15 (1848-75-5): Success\n",
      "Row 16 (2-[4-(5-bromo-3-methylpyridin-2-yl)butylamino]-5-[(6-methylpyridin-3-yl)methyl]-1,3-diazinan-4-one): Success\n",
      "Row 17 (m2l-663581): Success\n",
      "Row 18 (ritonavir): Success\n",
      "Row 19 (bis-hydroxylated-l-663581): Success\n",
      "Row 20 (nan): Success\n",
      "Row 21 (nan): Success\n",
      "Row 22 (raloxifene): Success\n",
      "Row 23 (telmesteine): Success\n",
      "Row 24 (chlorambucil): Success\n",
      "Row 25 (quercetin): Success\n",
      "Row 26 (sucrose): Success\n",
      "Row 27 (flurbiprofen): Success\n",
      "Row 28 (schembl18285121): Success\n",
      "Row 29 (d-mannitol): Success\n",
      "Row 30 (compound 34): Success\n",
      "Row 31 (y22): Success\n",
      "Row 32 (l4): Success\n",
      "Row 33 (chebi: 145922): Success\n",
      "Row 34 (guanidinothiazol analogue 17 ac1lbibi -- pubmed): Success\n",
      "Row 35 (cube-2): Success\n",
      "Row 36 (cube-6): Success\n",
      "Row 37 (cube-10): Success\n",
      "Row 38 (chembl151192): Success\n",
      "Row 39 (amethopterin): Success\n",
      "Row 40 (rifampicin): Success\n",
      "Row 41 (baclofen): Success\n",
      "Row 42 (etoposide): Success\n",
      "Row 43 (methotrexate): Success\n",
      "Row 44 (imatinib): Success\n",
      "Row 45 (.alpha.-d-ddc): Success\n",
      "Row 46 (mdl 63,246): CRASHED - PaDEL-Descriptor encountered an error: PaDEL-Descriptor timed out during subprocess call\n",
      "Row 47 (4-hydroxyalprazolam): Success\n",
      "Row 48 (etodolac): Success\n",
      "Row 49 (atenolol): Success\n",
      "Row 50 (cimetidine): Success\n",
      "Row 51 (cimetidine (y-g1)): Success\n",
      "Row 52 (biosone): Success\n",
      "Row 53 (vardenafil): Success\n",
      "Row 54 (151581-23-6): Success\n",
      "Row 55 (apaxifylline): Success\n",
      "Row 56 (chembl12325): Success\n",
      "Row 57 (sb 239063): Success\n",
      "Row 58 (sbb079053): Success\n",
      "Row 59 (4-aminobenzoic acid): Success\n",
      "Row 60 (nan): Success\n",
      "Row 61 (1,3-dimethyl-2-(2-methylphenylimino)imidazolidine): Success\n",
      "Row 62 (tz-17): Success\n",
      "Row 63 (atorvastatin): Success\n",
      "Row 64 (benzoylecgonine): Success\n",
      "Row 65 (monohydroxy l-663,581 metabolite): Success\n",
      "Row 66 (dcka): Success\n",
      "Row 67 (didanosine): Success\n",
      "Row 68 (sildenafil): Success\n",
      "Row 69 (sk&f 93319): Success\n",
      "Row 70 (sb-271406): Success\n",
      "Row 71 (indomethacin): Success\n",
      "Row 72 (skf 93319): Success\n",
      "Row 73 (n-(2,4-dimethylphenyl)-1,3-dimethylimidazolidin-2-imine): Success\n",
      "Row 74 (4794-83-6): Success\n",
      "Row 75 (schembl1704876): Success\n",
      "Row 76 (diclazuril): Success\n",
      "Row 77 (compound-9): Success\n",
      "Row 78 (yg19): Success\n",
      "Row 79 (17 zm0241385): Success\n",
      "Row 80 (diclofenac): Success\n",
      "Row 81 (l-dideoxyinosine): Success\n",
      "Row 82 (didanosine): Success\n",
      "Row 83 (α-hydroxyalprazolam (alpha-hydroxyalprazolam)): Success\n",
      "Row 84 (schembl13579049): Success\n",
      "Row 85 (zinc27644005): Success\n",
      "Row 86 (p-phenylbenzoic acid): Success\n",
      "Row 87 (nan): Success\n",
      "Row 88 (ls-190695): Success\n",
      "Row 89 (ranitidine): Success\n",
      "Row 90 (n-[3-[5-[(dimethylamino)methyl]furan-2-yl]sulfanylpropyl]-n'-methyl-2-nitroethanimidamide): Success\n",
      "Row 91 (chembl1907165): Success\n",
      "Row 92 (ranitidine base): Success\n",
      "Row 93 (nan): Success\n",
      "Row 94 (digoxin): Success\n",
      "Row 95 (compound 5): Success\n",
      "Row 96 (ftc; emtricitabine): Success\n",
      "Row 97 (cogoxin): Success\n",
      "Row 98 (nsc606170): Success\n",
      "Row 99 (2',3'-dideoxycytidine (zalcitabine)): Success\n",
      "Row 100 (y12): Success\n",
      "Row 101 (y-g12 (bbcpd10)): Success\n",
      "Row 102 (72801-60-6): Success\n",
      "Row 103 (chembl1950329): Success\n",
      "Row 104 (az599): Success\n",
      "Row 105 (miltefosine): Success\n",
      "Row 106 (acrivastine): Success\n",
      "Row 107 (compound 35): Success\n",
      "Row 108 (74188-86-6): Success\n",
      "Row 109 (bbcpd17): Success\n",
      "Row 110 (sulpiride): Success\n",
      "Row 111 (salicylic acid (2-hydroxybenzoic acid)): Success\n",
      "Row 112 (norfloxacin): Success\n",
      "Row 113 (bromocriptine): Success\n",
      "Row 114 (bromocriptine): Success\n",
      "Row 115 (ergotamine): Success\n",
      "Row 116 (lupitidine (y-g5; skf93479)): Success\n",
      "Row 117 (cytisine): Success\n",
      "Row 118 (amiodarone): Success\n",
      "Row 119 (lupitidine): Success\n",
      "Row 120 (zolmitriptan): Success\n",
      "Row 121 (127779-20-8): Success\n",
      "Row 122 (vincristine): Success\n",
      "Row 123 (vincristine): Success\n",
      "Row 124 (139264-82-7): Success\n",
      "Row 125 (fexofenadine (allegra)): Success\n",
      "Row 126 (proc-19m): Success\n",
      "Row 127 (ivermectin): Success\n",
      "Row 128 (chembl68445): Success\n",
      "Row 129 (oseltamivir): Success\n",
      "Row 130 (cadralazine): Success\n",
      "Row 131 (compound 17): Success\n",
      "Row 132 (ac1nfq3w): Success\n",
      "Row 133 (156154-71-1): Success\n",
      "Row 134 (dm-44): Success\n",
      "Row 135 (amezinium): Success\n",
      "Row 136 (-): Success\n",
      "Row 137 (ro65-7674): Success\n",
      "Row 138 (chembl3264225): Success\n",
      "Row 139 (celecoxib, celebrex): Success\n",
      "Row 140 (liarozole): Success\n",
      "Row 141 (ridogrel): Success\n",
      "Row 142 (chembl1185227): Success\n",
      "Row 143 (takle-2; l-779,450): Success\n",
      "Row 144 (saquinavir): Success\n",
      "Row 145 (anabet): Success\n",
      "Row 146 (156154-42-6): Success\n",
      "Row 147 (nelfinavir mesylate): Success\n",
      "Row 148 (nelfinavir): Success\n",
      "Row 149 (miloxacin): Success\n",
      "Row 150 (chembl243790): Success\n",
      "Row 151 (prazosin): Success\n",
      "Row 152 (glibenclamide): Success\n",
      "Row 153 (prednisone): Success\n",
      "Row 154 (161105-56-2): Success\n",
      "Row 155 (l001588): Success\n",
      "Row 156 (mk-0969): Success\n",
      "Row 157 (s118): Success\n",
      "Row 158 (4201-26-7): Success\n",
      "Row 159 (takle-1; sb-590885): Success\n",
      "Row 160 (sulfamethoxypyridazine): Success\n",
      "Row 161 (alovudine): Success\n",
      "Row 162 (chembl357268): Success\n",
      "Row 163 (nsc169534): Success\n",
      "Row 164 (doxorubicin): Success\n",
      "Row 165 (omeprazole): Success\n",
      "Row 166 (ly2066948): Success\n",
      "Row 167 (domperidone): Success\n",
      "Row 168 (aciclovir): Success\n",
      "Row 169 (tiotidine (skb10, y-g10)): Success\n",
      "Row 170 (penicillic acid): Success\n",
      "Row 171 (chembl213760): Success\n",
      "Row 172 (compound 4b [pmid: 16099654]): Success\n",
      "Row 173 (compound 13): Success\n",
      "Row 174 (colchicine): Success\n",
      "Row 175 (risperidone-9-oh): Success\n",
      "Row 176 (levodopa): Success\n",
      "Row 177 (d-phenylalanine-l-proline): Success\n",
      "Row 178 (2',3'-dideoxy-3'-hydroxymethylcytidine): Success\n",
      "Row 179 (penicillic acid): Success\n",
      "Row 180 (irie-16c): Success\n",
      "Row 181 (2´,3´-dideoxy-3´-hydroxymethylcytidine): Success\n",
      "Row 182 (cyclosporine a): Success\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m mol_name = row[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Calculate descriptors\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     descriptors = from_smiles(smi, descriptors=\u001b[38;5;28;01mTrue\u001b[39;00m, fingerprints=\u001b[38;5;28;01mFalse\u001b[39;00m, timeout=\u001b[32m45\u001b[39m)\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# Check if descriptors were actually returned\u001b[39;00m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m descriptors:\n\u001b[32m     37\u001b[39m         \u001b[38;5;66;03m# FIX IS HERE: Wrap 'descriptors' in brackets [ ] to make it a list\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hf/lib/python3.11/site-packages/padelpy/functions.py:116\u001b[39m, in \u001b[36mfrom_smiles\u001b[39m\u001b[34m(smiles, output_csv, descriptors, fingerprints, timeout, maxruntime, threads)\u001b[39m\n\u001b[32m    114\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    115\u001b[39m                 warnings.warn(e, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m kb_exception\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_csv, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m desc_file:\n\u001b[32m    119\u001b[39m     reader = DictReader(desc_file)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hf/lib/python3.11/site-packages/padelpy/functions.py:83\u001b[39m, in \u001b[36mfrom_smiles\u001b[39m\u001b[34m(smiles, output_csv, descriptors, fingerprints, timeout, maxruntime, threads)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m         padeldescriptor(\n\u001b[32m     84\u001b[39m             mol_dir=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.smi\u001b[39m\u001b[33m\"\u001b[39m.format(filename),\n\u001b[32m     85\u001b[39m             d_file=output_csv,\n\u001b[32m     86\u001b[39m             convert3d=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     87\u001b[39m             retain3d=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     88\u001b[39m             d_2d=descriptors,\n\u001b[32m     89\u001b[39m             d_3d=descriptors,\n\u001b[32m     90\u001b[39m             fingerprints=fingerprints,\n\u001b[32m     91\u001b[39m             sp_timeout=timeout,\n\u001b[32m     92\u001b[39m             retainorder=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     93\u001b[39m             maxruntime=maxruntime,\n\u001b[32m     94\u001b[39m             threads=threads\n\u001b[32m     95\u001b[39m         )\n\u001b[32m     96\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hf/lib/python3.11/site-packages/padelpy/wrapper.py:165\u001b[39m, in \u001b[36mpadeldescriptor\u001b[39m\u001b[34m(maxruntime, waitingjobs, threads, d_2d, d_3d, config, convert3d, descriptortypes, detectaromaticity, mol_dir, d_file, fingerprints, log, maxcpdperfile, removesalt, retain3d, retainorder, standardizenitro, standardizetautomers, tautomerlist, usefilenameasmolname, sp_timeout, headless)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m usefilenameasmolname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    163\u001b[39m     command += \u001b[33m'\u001b[39m\u001b[33m -usefilenameasmolname\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m _, err = _popen_timeout(command, sp_timeout)\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err != \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mPaDEL-Descriptor encountered an error: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m    168\u001b[39m         err.decode(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    169\u001b[39m     ))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hf/lib/python3.11/site-packages/padelpy/wrapper.py:43\u001b[39m, in \u001b[36m_popen_timeout\u001b[39m\u001b[34m(command, timeout)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(timeout):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         sleep(\u001b[32m1\u001b[39m)\n\u001b[32m     44\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m p.poll() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     45\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m p.communicate()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from padelpy import from_smiles\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 1. Load your input data\n",
    "input_file = '../data/combined_bbb_classification_fixed.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Output file name\n",
    "output_file = 'padel_results_loop.csv'\n",
    "\n",
    "# Check if file exists to resume\n",
    "if os.path.isfile(output_file):\n",
    "    print(f\"Resuming... appending to {output_file}\")\n",
    "    existing_df = pd.read_csv(output_file)\n",
    "    processed_count = len(existing_df)\n",
    "    print(f\"Already processed {processed_count} molecules.\")\n",
    "    df_to_process = df.iloc[processed_count:]\n",
    "else:\n",
    "    print(f\"Starting new output file: {output_file}\")\n",
    "    processed_count = 0\n",
    "    df_to_process = df\n",
    "\n",
    "print(f\"Processing {len(df_to_process)} molecules one by one...\")\n",
    "\n",
    "for index, row in df_to_process.iterrows():\n",
    "    smi = row['smiles']\n",
    "    mol_name = row['name']\n",
    "    \n",
    "    try:\n",
    "        # Calculate descriptors\n",
    "        descriptors = from_smiles(smi, descriptors=True, fingerprints=False, timeout=45)\n",
    "        \n",
    "        # Check if descriptors were actually returned\n",
    "        if descriptors:\n",
    "            # FIX IS HERE: Wrap 'descriptors' in brackets [ ] to make it a list\n",
    "            desc_row = pd.DataFrame([descriptors])\n",
    "            \n",
    "            # Add identifiers\n",
    "            desc_row.insert(0, 'Original_Name', mol_name)\n",
    "            desc_row.insert(1, 'Original_SMILES', smi)\n",
    "            \n",
    "            # Write to CSV\n",
    "            write_header = not os.path.isfile(output_file)\n",
    "            desc_row.to_csv(output_file, mode='a', index=False, header=write_header)\n",
    "            \n",
    "            print(f\"Row {index} ({mol_name}): Success\")\n",
    "        else:\n",
    "            print(f\"Row {index} ({mol_name}): FAILED (Empty result from PaDEL)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # This catches errors so the loop doesn't stop\n",
    "        print(f\"Row {index} ({mol_name}): CRASHED - {e}\")\n",
    "        \n",
    "    # Optional: small sleep to prevent Java from choking on rapid restart\n",
    "    # time.sleep(0.1)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3f97ea-7266-49a7-9b1c-872470e74583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV rows: 9637\n",
      "Excel rows before merge: 33\n",
      "New rows to add: 9633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = csv_df[col]\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = np.nan\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = np.nan\n",
      "/var/folders/sr/wdjmxmbx5lz8mb2nqmnbfvqm0000gp/T/ipykernel_92228/3265441432.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  csv_aligned[col] = np.nan\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "APIError: [401]: API keys are not supported by this API. Expected OAuth2 access token or other authentication credentials that assert a principal. See https://cloud.google.com/docs/authentication",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m result_df = pd.concat([excel_df, new_rows], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Update Google Sheet with merged data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m sheet.clear()  \u001b[38;5;66;03m# Clear existing data\u001b[39;00m\n\u001b[32m     64\u001b[39m sheet.update([result_df.columns.values.tolist()] + result_df.values.tolist())\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGoogle Sheet rows after merge: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(result_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hf/lib/python3.11/site-packages/gspread/worksheet.py:2211\u001b[39m, in \u001b[36mWorksheet.clear\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclear\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> JSONResponse:\n\u001b[32m   2210\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Clears all cells in the worksheet.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.values_clear(\n\u001b[32m   2212\u001b[39m         \u001b[38;5;28mself\u001b[39m.spreadsheet_id, absolute_range_name(\u001b[38;5;28mself\u001b[39m.title)\n\u001b[32m   2213\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hf/lib/python3.11/site-packages/gspread/http_client.py:204\u001b[39m, in \u001b[36mHTTPClient.values_clear\u001b[39m\u001b[34m(self, id, range)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Lower-level method that directly calls `spreadsheets/<ID>/values:clear <https://developers.google.com/sheets/api/reference/rest/v4/spreadsheets.values/clear>`_.\u001b[39;00m\n\u001b[32m    196\u001b[39m \n\u001b[32m    197\u001b[39m \u001b[33;03m:param str range: The `A1 notation <https://developers.google.com/sheets/api/guides/concepts#a1_notation>`_ of the values to clear.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m \u001b[33;03m.. versionadded:: 3.0\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m url = SPREADSHEET_VALUES_CLEAR_URL % (\u001b[38;5;28mid\u001b[39m, quote(\u001b[38;5;28mrange\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m r = \u001b[38;5;28mself\u001b[39m.request(\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url)\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hf/lib/python3.11/site-packages/gspread/http_client.py:128\u001b[39m, in \u001b[36mHTTPClient.request\u001b[39m\u001b[34m(self, method, endpoint, params, data, json, files, headers)\u001b[39m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIError(response)\n",
      "\u001b[31mAPIError\u001b[39m: APIError: [401]: API keys are not supported by this API. Expected OAuth2 access token or other authentication credentials that assert a principal. See https://cloud.google.com/docs/authentication"
     ]
    }
   ],
   "source": [
    "#adding current dataset to brainroute db \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gspread\n",
    "\n",
    "# File paths - update these with your actual file paths\n",
    "csv_file = '../data/combined_bbb_classification_fixed.csv'\n",
    "google_sheet_url = 'https://docs.google.com/spreadsheets/d/1sCVKMH_n-Uc-LLPxKhUi1g-XmKVOSlUQZGwrsrDVP_4/edit?gid=0#gid=0'  # Full URL of your Google Sheet\n",
    "worksheet_name = 'Sheet1'  # Name of the worksheet/tab\n",
    "api_key = 'AIzaSyAnJ_4h11oUrKy1XJK35scSIjJ1NEwDhZ8'  # Your Google Sheets API key\n",
    "\n",
    "# Set up Google Sheets authentication with API key\n",
    "client = gspread.auth.api_key(api_key)\n",
    "\n",
    "# Read the files\n",
    "csv_df = pd.read_csv(csv_file)\n",
    "\n",
    "# Open Google Sheet and read data\n",
    "sheet = client.open_by_url(google_sheet_url).worksheet(worksheet_name)\n",
    "excel_df = pd.DataFrame(sheet.get_all_records())\n",
    "\n",
    "print(f\"CSV rows: {len(csv_df)}\")\n",
    "print(f\"Excel rows before merge: {len(excel_df)}\")\n",
    "\n",
    "# Transform BBB column to prediction format (0 -> BBB-, 1 -> BBB+)\n",
    "if 'BBB' in csv_df.columns:\n",
    "    csv_df['prediction'] = csv_df['BBB'].apply(lambda x: 'BBB+' if x == 1 else 'BBB-')\n",
    "    csv_df = csv_df.drop(columns=['BBB'])\n",
    "\n",
    "# Get all columns from excel sheet\n",
    "excel_columns = excel_df.columns.tolist()\n",
    "\n",
    "# Create a dataframe for CSV data with Excel's column structure\n",
    "csv_aligned = pd.DataFrame()\n",
    "\n",
    "for col in excel_columns:\n",
    "    if col in csv_df.columns:\n",
    "        # Column exists in CSV, copy the data\n",
    "        csv_aligned[col] = csv_df[col]\n",
    "    else:\n",
    "        # Column doesn't exist in CSV, fill with NA\n",
    "        csv_aligned[col] = np.nan\n",
    "\n",
    "# Identify a unique key to check for duplicates\n",
    "# Update 'id' below with your actual unique identifier column name\n",
    "unique_key = 'name'  # Change this to your actual unique key column\n",
    "\n",
    "if unique_key in excel_columns and unique_key in csv_aligned.columns:\n",
    "    # Filter out rows that already exist in excel\n",
    "    existing_keys = excel_df[unique_key].values\n",
    "    new_rows = csv_aligned[~csv_aligned[unique_key].isin(existing_keys)]\n",
    "    print(f\"New rows to add: {len(new_rows)}\")\n",
    "else:\n",
    "    # If no unique key, add all CSV rows (may create duplicates)\n",
    "    new_rows = csv_aligned\n",
    "    print(\"Warning: No unique key specified, adding all CSV rows\")\n",
    "\n",
    "# Combine excel data with new CSV rows\n",
    "result_df = pd.concat([excel_df, new_rows], ignore_index=True)\n",
    "\n",
    "# Update Google Sheet with merged data\n",
    "sheet.clear()  # Clear existing data\n",
    "sheet.update([result_df.columns.values.tolist()] + result_df.values.tolist())\n",
    "\n",
    "print(f\"Google Sheet rows after merge: {len(result_df)}\")\n",
    "print(f\"Updated Google Sheet: {google_sheet_name}\")\n",
    "print(\"\\nColumn mapping summary:\")\n",
    "print(f\"- Google Sheet columns: {len(excel_columns)}\")\n",
    "print(f\"- CSV columns matched: {sum(1 for col in excel_columns if col in csv_df.columns or col == 'prediction')}\")\n",
    "print(f\"- Columns filled with NA: {sum(1 for col in excel_columns if col not in csv_df.columns and col != 'prediction')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89be54b-89ce-46e2-b9f4-6116e8d61c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afb20ef-0782-4b7d-992b-177f76540a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV rows: 9637\n",
      "CSV columns: ['Unnamed: 0', 'name', 'smiles', 'BBB', 'MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'HallKierAlpha', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAmideBonds', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumAtomStereoCenters', 'NumBridgeheadAtoms', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumHeterocycles', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'NumSpiroAtoms', 'NumUnspecifiedAtomStereoCenters', 'Phi', 'RingCount', 'MolLogP', 'MolMR', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea']\n",
      "Transformed BBB column to prediction column\n",
      "\n",
      "Google Sheet columns: ['ChemBL_ID', 'name', 'Smiles', 'Formula', 'MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'HallKierAlpha', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAmideBonds', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumAtomStereoCenters', 'NumBridgeheadAtoms', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumHeterocycles', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'NumSpiroAtoms', 'NumUnspecifiedAtomStereoCenters', 'Phi', 'RingCount', 'MolLogP', 'MolMR', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea', 'prediction', 'Confidence', 'Uncertainty', 'Models_Agreement']\n",
      "\n",
      "Aligned CSV data: 9637 rows\n",
      "Columns matched: 219\n",
      "Columns filled with NA: 6\n",
      "\n",
      "✓ Saved aligned data to: data_to_append.csv\n",
      "\n",
      "Next steps:\n",
      "1. Open your Google Sheet\n",
      "2. Go to the last row of data in the 'Sheet1' tab\n",
      "3. Open data_to_append.csv in Excel/Sheets\n",
      "4. Copy all data (Ctrl+A, then Ctrl+C)\n",
      "5. Paste into your Google Sheet below the last row\n",
      "\n",
      "Or use Google Sheets import:\n",
      "1. File > Import\n",
      "2. Upload data_to_append.csv\n",
      "3. Choose 'Append to current sheet'\n",
      "4. Click Import\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File paths - update these with your actual file paths\n",
    "csv_file = '../data/combined_bbb_classification_fixed.csv'\n",
    "google_sheet_url = 'https://docs.google.com/spreadsheets/d/1sCVKMH_n-Uc-LLPxKhUi1g-XmKVOSlUQZGwrsrDVP_4/edit?gid=0#gid=0'  # Full URL of your Google Sheet\n",
    "worksheet_name = 'Sheet1'  # Name of the worksheet/tab where you want to append data\n",
    "\n",
    "# Read the CSV\n",
    "csv_df = pd.read_csv(csv_file)\n",
    "\n",
    "print(f\"CSV rows: {len(csv_df)}\")\n",
    "print(f\"CSV columns: {list(csv_df.columns)}\")\n",
    "\n",
    "# Transform BBB column to prediction format (0 -> BBB-, 1 -> BBB+)\n",
    "if 'BBB' in csv_df.columns:\n",
    "    csv_df['prediction'] = csv_df['BBB'].apply(lambda x: 'BBB+' if x == 1 else 'BBB-')\n",
    "    csv_df = csv_df.drop(columns=['BBB'])\n",
    "    print(\"Transformed BBB column to prediction column\")\n",
    "\n",
    "# Open the Google Sheet manually in your browser and:\n",
    "# 1. Make sure you're logged in\n",
    "# 2. Go to File > Download > Comma-separated values (.csv)\n",
    "# 3. Save it as 'existing_sheet.csv'\n",
    "# Then read it here to get the column structure\n",
    "existing_sheet_file = '../data/Neurogate_database - Sheet1.csv'  # Download your current Google Sheet as CSV\n",
    "\n",
    "try:\n",
    "    existing_df = pd.read_csv(existing_sheet_file)\n",
    "    excel_columns = existing_df.columns.tolist()\n",
    "    print(f\"\\nGoogle Sheet columns: {excel_columns}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nCouldn't find existing_sheet.csv. Using CSV columns as-is.\")\n",
    "    excel_columns = csv_df.columns.tolist()\n",
    "\n",
    "# Align CSV data with Google Sheet columns\n",
    "aligned_data = {}\n",
    "for col in excel_columns:\n",
    "    if col in csv_df.columns:\n",
    "        aligned_data[col] = csv_df[col]\n",
    "    else:\n",
    "        aligned_data[col] = np.nan\n",
    "\n",
    "csv_aligned = pd.DataFrame(aligned_data)\n",
    "\n",
    "print(f\"\\nAligned CSV data: {len(csv_aligned)} rows\")\n",
    "print(f\"Columns matched: {sum(1 for col in excel_columns if col in csv_df.columns)}\")\n",
    "print(f\"Columns filled with NA: {sum(1 for col in excel_columns if col not in csv_df.columns)}\")\n",
    "\n",
    "# Save the aligned data to a new CSV file\n",
    "output_file = 'data_to_append.csv'\n",
    "csv_aligned.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved aligned data to: {output_file}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Open your Google Sheet\")\n",
    "print(f\"2. Go to the last row of data in the '{worksheet_name}' tab\")\n",
    "print(f\"3. Open {output_file} in Excel/Sheets\")\n",
    "print(\"4. Copy all data (Ctrl+A, then Ctrl+C)\")\n",
    "print(\"5. Paste into your Google Sheet below the last row\")\n",
    "print(\"\\nOr use Google Sheets import:\")\n",
    "print(\"1. File > Import\")\n",
    "print(f\"2. Upload {output_file}\")\n",
    "print(\"3. Choose 'Append to current sheet'\")\n",
    "print(\"4. Click Import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe74a8e-c1f1-4a25-a04e-c204ba5d2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"../data/padel_results_loop.csv\")\n",
    "columns_with_na = df.columns[df.isnull().any()].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327aafef-bef2-4598-a4a7-78f5d7d5e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717\n"
     ]
    }
   ],
   "source": [
    "print(len(columns_with_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff828cab-3814-4d8d-9b96-682c6cca49d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a5e62a-ac13-4915-af4b-0706f4b3cf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original_Name      1099\n",
      "Original_SMILES       0\n",
      "nAcid                 0\n",
      "ALogP                64\n",
      "ALogp2               64\n",
      "                   ... \n",
      "Ts                 2586\n",
      "As                 2586\n",
      "Vs                 2586\n",
      "Ks                 2586\n",
      "Ds                 2588\n",
      "Length: 1877, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38a47f-7c0b-40bc-b35b-2620cf83f0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hf)",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
